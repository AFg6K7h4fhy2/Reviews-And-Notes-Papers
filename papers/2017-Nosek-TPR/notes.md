# The Preregistration Revolution

```
@article{nosek2018preregistration,
  title={The preregistration revolution},
  author={Nosek, Brian A and Ebersole, Charles R and DeHaven, Alexander C and Mellor, David T},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={11},
  pages={2600--2606},
  year={2018},
  publisher={National Acad Sciences}
}
```

__Proposed Questions__

* How true is the statement: "_Forecasting is the strongest form of preregistration_"
* How should we think about the value of preregistration and/or the forecasting problem in non-NHST (null hypothesis significance testing) contexts?

> This paper focuses on NHST [Null hypothesis significance testing] because of its pervasive use (e.g., refs. 28 and 29). The opportunities and challenges discussed are somewhat different with other statistical approaches, such as Bayesian methods. However, no statistical method on its own avoids researcher opportunity for flexibility in analytical decisions, such as exclusion criteria or the creation of variables (30).

## Summary

The abstract:

> Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations.This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning,such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes—a process called pre-registration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.

The conclusion:

> Sometimes researchers use existing observations of nature to generate ideas about how the world works. This is called post-diction. Other times, researchers have an idea about how the world works and make new observations to test whether that idea is a reasonable explanation. This is called prediction. To make confident inferences, it is important to know which is which.Preregistration solves this challenge by requiring researchers to state how they will analyze the data before they observe it,allowing them to confront a prediction with the possibility of being wrong. Preregistration improves the interpretability and credibility of research findings/

## Notes

* Why is it so inconvenient for researchers to make distinctions between postdiction and prediction in their work? What tools, standards, or procedures might remedy this?
  * See two sentences down: "_An effective solution is to define the research questions and analysis plan before observing the research outcomes—a process called pre-registration._"
* Nice description of scientific workflow: "_Progress in science is marked by reducing uncertainty about nature. Scientists generate models that may explain prior observations and predict future observations. Those models are approximations and simplifications of reality. Models are iteratively improved and replaced by reducing the amount of pre- diction error. As prediction error decreases, certainty about what will occur in the future increases._"
* George Box’s aphorism: "_All models are wrong but some are useful_"
* Continuing on the production of science and distinctions in modes of research: "_Scientists improve models by generating hypotheses based on existing observations and testing those hypotheses by obtaining new observations...hypothesis-generating versus hypothesis-testing, the context of discovery versus the context of justification, data-independent versus data-contingent analysis, and exploratory versus confirmatory research_"
* Postdiction, using data to explore why something occurred versus prediction, getting data to test ideas about what will occur. Analogy might be using training data to understand the phenomenon and then getting test data for model validation.
* On the ills of not distinguishing post- and pre-dictions: "_Presenting postdictions as predictions can increase the attractiveness and publishability of findings by falsely reducing uncertainty. Ultimately, this decreases reproducibility_"
* The human in the research process failing to distinguish: "_It is an example of circular reasoning—generating a hypothesis based on observing data, and then evaluating the validity of the hypothesis based on the same data_"
* Very nice section on incentives in science and the effects on science of inadequacies introduced via human bias: "_The values of impartiality and objectivity are pervasive (16),particularly for scientists, but human reasoning is not reliably impartial or objective (17, 18). Scientists are motivated to ad-vance knowledge; scientists are also motivated to obtain job security, awards, publications, and grants. In the present research culture, these rewards are more likely to be secured by obtaining certain kinds of research outcomes over others. Novel results are rewarded more than redundant or incremental additions to existing knowledge. Positive results––finding a relationship between variables or an effect of treatments on outcomes––are rewarded more than negative results––failing to find a relation-ship or effect; clean results that provide a strong narrative are rewarded more than outcomes that show uncertainty or exceptions to the favored narrative (9, 19–21). Novel, positive, clean results are better results both for reward and for launching science into new domains of inquiry. However, achieving novel,positive, clean results is a rare event. Progress in research is halting, messy, and uncertain. The incentives for such results combined with their infrequency create a potential conflict of interest for the researcher. If certain kinds of results are more rewarded than others, then researchers are motivated to obtain results that are more likely to be rewarded regardless of the accuracy of those results._"
* Null hypothesis significance testing (NHST) is designed for prediction—testing hypothesis nor postdiction—generating hypothesis.
* "_If there were only one inference test to perform and only one way to conduct that test, then the P value is diagnostic about its intended likelihood. It is not hyperbole to say that this almost never occurs._"
* A nice analogy: "_Gelman and Loken (37) refer to the problem as the garden of forking paths. There are a vast number of choices for analyzing data that could be made. If those choices are made during analysis, observing the data may make selecting some paths more likely and others less likely. By the end, it may be impossible to estimate the paths that could have been selected if the data had looked different or if analytic decisions were influenced by hindsight, confirmation,and outcome biases. This leaves the observed P values with un-known diagnosticity, rendering them uninterpretable. In other words, NHST cannot be used with confidence for postdiction_"

Stopped notes after: Preregistration Distinguishes Prediction and Postdiction

# Modest Pre-Registration

## Summary

https://statmodeling.stat.columbia.edu/2023/12/04/modest-pre-registration/


## Notes


# Exploring Pre-Registration For Predictive Modeling

## Summary

https://statmodeling.stat.columbia.edu/2023/12/06/exploring-pre-registration-for-predictive-modeling/


## Notes


# Of Course Its Preregistered. Just Give Me A Sec

## Summary

https://statmodeling.stat.columbia.edu/2023/11/21/of-course-its-preregistered-just-give-me-a-sec/
## Notes
